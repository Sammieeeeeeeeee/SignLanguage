{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUSOWDRRIh7U",
        "outputId": "87e65758-e33b-44ff-8912-5518d364e363"
      },
      "outputs": [],
      "source": [
        "# method to mount data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saHE4JLiE5Sc"
      },
      "source": [
        "# MediaPipe Landmark Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "F28Blehi21Qx",
        "outputId": "7ae20d36-b162-4b3b-aabd-c2855337f43d"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install mediapipe==0.10.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThFSIPhF240q"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO-8LWsX3Bf9"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "    results = model.process(image)\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    return image, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoFHZd6b3F4S"
      },
      "outputs": [],
      "source": [
        "def draw_landmarks(image, results):\n",
        "    mp_holistic = mp.solutions.holistic  # Holistic model\n",
        "    mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
        "    # Draw left hand connections\n",
        "    image = mp_drawing.draw_landmarks(\n",
        "            image,\n",
        "            landmark_list=results.left_hand_landmarks,\n",
        "            connections=mp_holistic.HAND_CONNECTIONS,\n",
        "            landmark_drawing_spec=mp_drawing.DrawingSpec(\n",
        "                color=(232, 254, 255), thickness=1, circle_radius=4\n",
        "            ),\n",
        "            connection_drawing_spec=mp_drawing.DrawingSpec(\n",
        "                color=(255, 249, 161), thickness=2, circle_radius=2\n",
        "            ),\n",
        "    )\n",
        "    # Draw right hand connections\n",
        "    image = mp_drawing.draw_landmarks(\n",
        "            image,\n",
        "            landmark_list=results.right_hand_landmarks,\n",
        "            connections=mp_holistic.HAND_CONNECTIONS,\n",
        "            landmark_drawing_spec=mp_drawing.DrawingSpec(\n",
        "                color=(232, 254, 255), thickness=1, circle_radius=4\n",
        "            ),\n",
        "            connection_drawing_spec=mp_drawing.DrawingSpec(\n",
        "                color=(255, 249, 161), thickness=2, circle_radius=2\n",
        "            ),\n",
        "    )\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKwPeO-e3o-x"
      },
      "source": [
        "Split the dataset to Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnR13F5R3HoD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "video_dir = \"DTW Dataset/MSL_Basic\" # path to the MSL_Basic dataset\n",
        "output_dir = \"DTW Dataset/MSL_Basic/\" # path to the MSL_Basic dataset\n",
        "\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "train_ratio = 0.8\n",
        "test_ratio = 0.2\n",
        "\n",
        "for class_name in os.listdir(video_dir):\n",
        "    class_path = os.path.join(video_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(class_path) if f.endswith(('.mp4', 'mov', 'mkv'))]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    split_index = int(len(files) * train_ratio)\n",
        "    train_files = files[:split_index]\n",
        "    test_files = files[split_index:]\n",
        "\n",
        "    # Create subfolders for this class in train and test\n",
        "    train_class_dir = os.path.join(train_dir, class_name)\n",
        "    test_class_dir = os.path.join(test_dir, class_name)\n",
        "    os.makedirs(train_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "    # Move/copy files to the appropriate folders\n",
        "    for f in train_files:\n",
        "        shutil.copy(os.path.join(class_path, f), os.path.join(train_class_dir, f))\n",
        "    for f in test_files:\n",
        "        shutil.copy(os.path.join(class_path, f), os.path.join(test_class_dir, f))\n",
        "\n",
        "    print(f\"Class '{class_name}': {len(train_files)} train, {len(test_files)} test files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOMBDQA53gvS"
      },
      "source": [
        "Extract landmarks for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ38mYth3W0u"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Holistic\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "holistic_model = mp_holistic.Holistic(static_image_mode=False)\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"DTW Dataset/MSL_Basic/train/\" # path to the MSL_Basic train dataset\n",
        "output_base = \"DTW Dataset/MSL_Basic_Processed/train/\" # path to the MSL_Basic_Processed train dataset\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    output_class_path = os.path.join(output_base, class_name)\n",
        "    os.makedirs(output_class_path, exist_ok=True)\n",
        "\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing class folder: {class_name}\")\n",
        "\n",
        "    for video_file in os.listdir(class_path):\n",
        "        if not video_file.endswith((\".mp4\", \".mov\", \".mkv\")):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(class_path, video_file)\n",
        "        output_video_path = os.path.join(output_class_path, f\"processed_{video_file}\")\n",
        "        npy_output_path = os.path.join(output_class_path, f\"{os.path.splitext(video_file)[0]}.npy\")\n",
        "\n",
        "        print(f\"Processing video: {video_path}\")\n",
        "        capture = cv2.VideoCapture(video_path)\n",
        "        if not capture.isOpened():\n",
        "            print(f\"Failed to open video {video_path}\")\n",
        "            continue\n",
        "\n",
        "        # Output video writer setup\n",
        "        frame_width = 800\n",
        "        frame_height = 600\n",
        "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "        # Store landmarks\n",
        "        left_hand_sequence = []\n",
        "        right_hand_sequence = []\n",
        "\n",
        "        while capture.isOpened():\n",
        "            ret, frame = capture.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.resize(frame, (frame_width, frame_height))\n",
        "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            image.flags.writeable = False\n",
        "            results = holistic_model.process(image)\n",
        "            image.flags.writeable = True\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Draw and extract landmarks\n",
        "            if results.face_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
        "                    mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=1, circle_radius=1),\n",
        "                    mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1)\n",
        "                )\n",
        "\n",
        "            if results.right_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "                right = [[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark]\n",
        "            else:\n",
        "                right = [[0, 0, 0]] * 21  # 21 keypoints\n",
        "\n",
        "            if results.left_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "                left = [[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark]\n",
        "            else:\n",
        "                left = [[0, 0, 0]] * 21\n",
        "\n",
        "            left_hand_sequence.append(left)\n",
        "            right_hand_sequence.append(right)\n",
        "\n",
        "            out.write(image)\n",
        "\n",
        "        capture.release()\n",
        "        out.release()\n",
        "\n",
        "        # Save landmarks as .npy\n",
        "        landmarks_data = {\n",
        "            \"left\": np.array(left_hand_sequence),     # shape: (frames, 21, 3)\n",
        "            \"right\": np.array(right_hand_sequence),   # shape: (frames, 21, 3)\n",
        "            \"label\": class_name\n",
        "        }\n",
        "        np.save(npy_output_path, landmarks_data)\n",
        "        print(f\"Saved: {output_video_path} and {npy_output_path}\")\n",
        "\n",
        "# Cleanup\n",
        "holistic_model.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v01ntDC3lDz"
      },
      "source": [
        "Extract landmark for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAiC7G4p3crC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Holistic\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "holistic_model = mp_holistic.Holistic(static_image_mode=False)\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"DTW Dataset/MSL_Basic/test/\" # path to the MSL_Basic test dataset\n",
        "output_base = \"DTW Dataset/MSL_Basic_Processed/test/\" # path to the MSL_Basic_Processed test dataset\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    output_class_path = os.path.join(output_base, class_name)\n",
        "    os.makedirs(output_class_path, exist_ok=True)\n",
        "\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing class folder: {class_name}\")\n",
        "\n",
        "    for video_file in os.listdir(class_path):\n",
        "        if not video_file.endswith((\".mp4\", \".mov\", \".mkv\")):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(class_path, video_file)\n",
        "        output_video_path = os.path.join(output_class_path, f\"processed_{video_file}\")\n",
        "        npy_output_path = os.path.join(output_class_path, f\"{os.path.splitext(video_file)[0]}.npy\")\n",
        "\n",
        "        print(f\"Processing video: {video_path}\")\n",
        "        capture = cv2.VideoCapture(video_path)\n",
        "        if not capture.isOpened():\n",
        "            print(f\"Failed to open video {video_path}\")\n",
        "            continue\n",
        "\n",
        "        # Output video writer setup\n",
        "        frame_width = 800\n",
        "        frame_height = 600\n",
        "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "        # Store landmarks\n",
        "        left_hand_sequence = []\n",
        "        right_hand_sequence = []\n",
        "\n",
        "        while capture.isOpened():\n",
        "            ret, frame = capture.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.resize(frame, (frame_width, frame_height))\n",
        "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            image.flags.writeable = False\n",
        "            results = holistic_model.process(image)\n",
        "            image.flags.writeable = True\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Draw and extract landmarks\n",
        "            if results.face_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
        "                    mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=1, circle_radius=1),\n",
        "                    mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1)\n",
        "                )\n",
        "\n",
        "            if results.right_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "                right = [[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark]\n",
        "            else:\n",
        "                right = [[0, 0, 0]] * 21  # 21 keypoints\n",
        "\n",
        "            if results.left_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "                left = [[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark]\n",
        "            else:\n",
        "                left = [[0, 0, 0]] * 21\n",
        "\n",
        "            left_hand_sequence.append(left)\n",
        "            right_hand_sequence.append(right)\n",
        "\n",
        "            out.write(image)\n",
        "\n",
        "        capture.release()\n",
        "        out.release()\n",
        "\n",
        "        # Save landmarks as .npy\n",
        "        landmarks_data = {\n",
        "            \"left\": np.array(left_hand_sequence),     # shape: (frames, 21, 3)\n",
        "            \"right\": np.array(right_hand_sequence),   # shape: (frames, 21, 3)\n",
        "            \"label\": class_name\n",
        "        }\n",
        "        np.save(npy_output_path, landmarks_data)\n",
        "        print(f\"Saved: {output_video_path} and {npy_output_path}\")\n",
        "\n",
        "# Cleanup\n",
        "holistic_model.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLt_0SeA329K"
      },
      "source": [
        "# DTW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-aK_Yvv34f0",
        "outputId": "b4b4ee1f-0db5-4ff3-aa91-95568191f389"
      },
      "outputs": [],
      "source": [
        "!pip install fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UIBXfrb3-Iz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_dir = \"DTW Dataset/MSL_Basic_Processed/train/\" # path to the MSL_Basic_Processed train dataset\n",
        "train_samples = []\n",
        "\n",
        "# Load each .npy file from class subfolders\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "    for file_name in os.listdir(class_path):\n",
        "        if file_name.endswith(\".npy\"):\n",
        "            data = np.load(os.path.join(class_path, file_name), allow_pickle=True).item()\n",
        "            left = data[\"left\"].reshape(-1, 63)   # (T, 63)\n",
        "            right = data[\"right\"].reshape(-1, 63) # (T, 63)\n",
        "            label = data[\"label\"]\n",
        "            train_samples.append({\"left\": left, \"right\": right, \"label\": label})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mmWwNHn3-s_"
      },
      "outputs": [],
      "source": [
        "train_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ho8SGFe3_sK"
      },
      "outputs": [],
      "source": [
        "from fastdtw import fastdtw\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def compute_total_dtw(test_left, test_right, train_left, train_right):\n",
        "    # DTW for each hand\n",
        "    dist_left, _ = fastdtw(test_left, train_left, dist=euclidean)\n",
        "    dist_right, _ = fastdtw(test_right, train_right, dist=euclidean)\n",
        "    return dist_left + dist_right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVCvT4sM4Cfu"
      },
      "outputs": [],
      "source": [
        "def predict_sign(test_data, train_samples):\n",
        "    test_left = test_data[\"left\"].reshape(-1, 63)\n",
        "    test_right = test_data[\"right\"].reshape(-1, 63)\n",
        "\n",
        "    min_distance = float(\"inf\")\n",
        "    predicted_label = None\n",
        "\n",
        "    for sample in train_samples:\n",
        "        dist = compute_total_dtw(test_left, test_right, sample[\"left\"], sample[\"right\"])\n",
        "        if dist < min_distance:\n",
        "            min_distance = dist\n",
        "            predicted_label = sample[\"label\"]\n",
        "\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp9dfao34Dui"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "test_path = \"DTW Dataset/MSL_Basic_Processed/test/Sorry/Sorry_01.npy\" # path to a testing file\n",
        "test_data = np.load(test_path, allow_pickle=True).item()\n",
        "\n",
        "predicted = predict_sign(test_data, train_samples)\n",
        "print(\"Predicted Sign:\", predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTnlXiQb4Jud"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "test_root = \"DTW Dataset/MSL_Basic_Processed/test/\" # path to a test folder\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for class_dir in os.listdir(test_root):\n",
        "    class_path = os.path.join(test_root, class_dir)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    for file_name in os.listdir(class_path):\n",
        "        if not file_name.endswith(\".npy\"):\n",
        "            continue\n",
        "\n",
        "        test_file_path = os.path.join(class_path, file_name)\n",
        "        test_sample = np.load(test_file_path, allow_pickle=True).item()\n",
        "\n",
        "        # Predict the sign using DTW\n",
        "        predicted_label = predict_sign(test_sample, train_samples)\n",
        "\n",
        "        y_true.append(test_sample['label'])      # actual label\n",
        "        y_pred.append(predicted_label)           # predicted label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVs_V-yR4KTs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(\"DTW Classification Accuracy:\", accuracy)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SavQG4Cw4N3R"
      },
      "source": [
        "Convert npy files to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKlgduEk4Nmk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "base = \"DTW Dataset/MSL_Basic_Processed/train/\" # path to a train folder\n",
        "for cls in os.listdir(base):\n",
        "    class_dir = os.path.join(base, cls)\n",
        "    if not os.path.isdir(class_dir):\n",
        "        continue\n",
        "\n",
        "    for npy_file in os.listdir(class_dir):\n",
        "        if npy_file.endswith(\".npy\"):\n",
        "            data_path = os.path.join(class_dir, npy_file)\n",
        "            data = np.load(data_path, allow_pickle=True).item()\n",
        "\n",
        "            out = {\n",
        "                \"left\": data[\"left\"].tolist(),   # Convert ndarray to list\n",
        "                \"right\": data[\"right\"].tolist(), # Convert ndarray to list\n",
        "                \"label\": data[\"label\"]\n",
        "            }\n",
        "\n",
        "            json_path = os.path.join(class_dir, npy_file.replace(\".npy\", \".json\"))\n",
        "            with open(json_path, \"w\") as f:\n",
        "                json.dump(out, f)\n",
        "\n",
        "            print(f\"Saved JSON: {json_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
